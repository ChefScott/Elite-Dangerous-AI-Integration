name: Build Executable

on: [push, pull_request]

jobs:
  pyinstaller-build:
    runs-on: windows-latest

    steps:
      - name: Check out the repository
        uses: actions/checkout@v2

      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install pyinstaller
        run: |
          $Env:PYINSTALLER_COMPILE_BOOTLOADER = "true"
          pip install --user --force-reinstall --ignore-installed --no-binary :all: pyinstaller==6.10.0

      - name: Determine paths for dependencies
        id: determine_paths
        run: |
          $ONNXRUNTIME_DLL = python -c 'import os, onnxruntime; print(os.path.join(os.path.dirname(onnxruntime.__file__), "capi", "onnxruntime_providers_shared.dll"))'
          $LLAMACPP_DLL = python -c 'import os, llama_cpp; print(os.path.join(os.path.dirname(llama_cpp.__file__), "lib", "llama.dll"))'
          $VAD_MODEL = python -c 'import os, pysilero_vad; print(os.path.join(os.path.dirname(pysilero_vad.__file__), "models", "silero_vad.onnx"))'
          echo "ONNXRUNTIME_DLL=$ONNXRUNTIME_DLL" >> $env:GITHUB_ENV
          echo "LLAMACPP_DLL=$LLAMACPP_DLL" >> $env:GITHUB_ENV
          echo "VAD_MODEL=$VAD_MODEL" >> $env:GITHUB_ENV
          python -c 'import onnxruntime; print("onnxruntime path:", onnxruntime.__file__)'
          python -c 'import llama_cpp; print("llama_cpp path:", llama_cpp.__file__)'
          python -c 'import pysilero_vad; print("pysilero_vad path:", pysilero_vad.__file__)'

      - name: Debug environment variables
        run: |
          echo "ONNXRUNTIME_DLL=${{ env.ONNXRUNTIME_DLL }}"
          echo "LLAMACPP_DLL=${{ env.LLAMACPP_DLL }}"
          echo "VAD_MODEL=${{ env.VAD_MODEL }}"

      - name: Create Executable for AIGUI
        run: |
          pyinstaller .\src\AIGUI.py -y --onedir --clean --noconsole --add-data .\docs\screen\EDAI_logo.png:.\screen

      - name: Create Executable for Chat
        run: |
          pyinstaller .\src\Chat.py -y --onedir --clean --console --hidden-import=comtypes.stream --add-data ${{ env.VAD_MODEL }}:.\pysilero_vad\models --add-binary ${{ env.ONNXRUNTIME_DLL }}:.

      - name: Create Executable for AIServer
        run: |
          pyinstaller .\src\AIServer.py -y --onedir --clean --console --hidden-import=comtypes.stream --add-binary ${{ env.ONNXRUNTIME_DLL }}:. --add-binary ${{ env.LLAMACPP_DLL }}:.\llama_cpp\lib

      - name: Get current commit ID
        id: get_commit
        run: |
          $COMMIT_ID = git rev-parse HEAD
          echo "COMMIT_ID=$COMMIT_ID" >> $env:GITHUB_ENV

      - name: Create start.bat script
        run: |
          $commitId = "${{ env.COMMIT_ID }}"
          $start = "@echo off`r`nstart """" .\\AIGUI\\AIGUI.exe --chat=Chat\\Chat.exe --release=$commitId`r`nexit"
          $start | Out-File -Encoding ASCII .\\dist\\start.bat

      - name: Upload build artifact
        uses: actions/upload-artifact@v4
        with:
          name: COVAS_NEXT_v${{ env.COMMIT_ID }}
          path: ./dist
          compression-level: 0 # no compression

      - name: Add msbuild to PATH
        uses: microsoft/setup-msbuild@v2

      - name: Install Vulkan SDK
        uses: humbletim/install-vulkan-sdk@v1.1.1
        with:
          version: 1.3.261.1
          cache: true

      - name: Install llamacpp with Vulkan support
        run: |
          pip install --upgrade pip setuptools
          $Env:CMAKE_ARGS = "-DGGML_VULKAN=on"
          pip install --force-reinstall llama-cpp-python==0.2.90

      - name: Create Executable for AIServer with llamacpp[vulkan]
        run: |
          pyinstaller .\src\AIServer.py -y --onedir --clean --console --hidden-import=comtypes.stream --add-binary ${{ env.ONNXRUNTIME_DLL }}:. --add-binary ${{ env.LLAMACPP_DLL }}:.\llama_cpp\lib

      - name: Upload build artifact
        uses: actions/upload-artifact@v4
        with:
          name: COVAS_NEXT_v${{ env.COMMIT_ID }}-vulkan
          path: ./dist
          compression-level: 0 # no compression
